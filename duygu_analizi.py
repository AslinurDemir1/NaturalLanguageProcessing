import torch
import torch.nn as nn
import torch.optim as optim

# --- 1. VERÄ° SETÄ° (Label: 1=Olumlu, 0=Olumsuz) ---
data = [
    ("bu Ã¼rÃ¼n harika Ã§ok beÄŸendim", 1),
    ("mÃ¼kemmel bir film kesinlikle izleyin", 1),
    ("tam bir hayal kÄ±rÄ±klÄ±ÄŸÄ± berbat", 0),
    ("hiÃ§ beÄŸenmedim paranÄ±za yazÄ±k", 0),
    ("kargo Ã§ok hÄ±zlÄ± geldi teÅŸekkÃ¼rler", 1),
    ("bozuk Ã§Ä±ktÄ± iade edeceÄŸim", 0),
    ("fiyat performans Ã¼rÃ¼nÃ¼ gayet iyi", 1),
    ("sakÄ±n almayÄ±n Ã§ok kalitesiz", 0)
]

# --- 2. SÃ–ZLÃœK OLUÅTURMA (MÃ¼hendislik KÄ±smÄ±) ---
# TÃ¼m cÃ¼mlelerde geÃ§en kelimeleri tek bir havuzda toplayalÄ±m
word_to_ix = {} # Kelime -> SayÄ± HaritasÄ±
for sent, label in data:
    for word in sent.split():
        if word not in word_to_ix:
            word_to_ix[word] = len(word_to_ix)

VOCAB_SIZE = len(word_to_ix)
NUM_LABELS = 2 # Olumlu (1) veya Olumsuz (0)

print(f"SÃ¶zlÃ¼k Boyutu: {VOCAB_SIZE} kelime")
print(f"Ã–rnek SÃ¶zlÃ¼k: {list(word_to_ix.items())[:5]}...")

# --- 3. VEKTÃ–RLEÅTÄ°RME FONKSÄ°YONU (Bag of Words) ---
def make_bow_vector(sentence, word_to_ix):
    # Ã–nce tÃ¼m sÃ¶zlÃ¼k kadar 0'lardan oluÅŸan bir vektÃ¶r yap
    vec = torch.zeros(len(word_to_ix))
    # CÃ¼mledeki kelimelerin olduÄŸu yerleri 1 yap (veya sayÄ±sÄ±nÄ± artÄ±r)
    for word in sentence.split():
        if word in word_to_ix: # EÄŸer kelimeyi tanÄ±yorsak
            vec[word_to_ix[word]] += 1
    return vec.view(1, -1) # Boyut ekle: [1, VOCAB_SIZE]

# --- 4. MODEL MÄ°MARÄ°SÄ° ---
class DuyguAnalizModeli(nn.Module):
    def __init__(self, vocab_size, num_labels):
        super(DuyguAnalizModeli, self).__init__()
        # Girdi: SÃ¶zlÃ¼k boyutu kadar (Ã–rn: 30 nÃ¶ron)
        # Ã‡Ä±ktÄ±: 2 nÃ¶ron (Olumlu/Olumsuz skoru)
        self.linear = nn.Linear(vocab_size, num_labels)
        self.softmax = nn.LogSoftmax(dim=1) # OlasÄ±lÄ±ÄŸa Ã§evir

    def forward(self, x):
        return self.softmax(self.linear(x))

model = DuyguAnalizModeli(VOCAB_SIZE, NUM_LABELS)

# --- 5. EÄÄ°TÄ°M ---
loss_function = nn.NLLLoss() # Negative Log Likelihood (SÄ±nÄ±flandÄ±rma iÃ§in)
optimizer = optim.SGD(model.parameters(), lr=0.1)

print("\nModel EÄŸitiliyor...")
for epoch in range(100): # 100 tur dÃ¶n
    for sentence, label in data:
        # A. HazÄ±rlÄ±k
        model.zero_grad()
        bow_vec = make_bow_vector(sentence, word_to_ix) # CÃ¼mleyi vektÃ¶re Ã§evir
        target = torch.tensor([label], dtype=torch.long) # Hedefi tensÃ¶r yap

        # B. Ä°leri ve Geri YayÄ±lÄ±m
        log_probs = model(bow_vec)       # Tahmin et
        loss = loss_function(log_probs, target) # HatayÄ± bul
        loss.backward()                  # TÃ¼rev al
        optimizer.step()                 # GÃ¼ncelle

print("EÄŸitim TamamlandÄ±!")

# --- 6. TEST (GERÃ‡EK DÃœNYA) ---
def tahmin_et(test_cumlesi):
    with torch.no_grad():
        bow_vec = make_bow_vector(test_cumlesi, word_to_ix)
        log_probs = model(bow_vec)
        # En yÃ¼ksek skoru al
        tahmin_index = torch.argmax(log_probs, dim=1).item()
        
        durum = "OLUMLU ğŸ˜Š" if tahmin_index == 1 else "OLUMSUZ ğŸ˜¡"
        print(f"CÃ¼mle: '{test_cumlesi}' -> {durum}")

print("\n--- SONUÃ‡LAR ---")
tahmin_et("bu film harika")       # SÃ¶zlÃ¼kte var
tahmin_et("Ã¼rÃ¼n berbat sakÄ±n almayÄ±n") # SÃ¶zlÃ¼kte var
tahmin_et("kargo hÄ±zlÄ± geldi")    # SÃ¶zlÃ¼kte var
# Dikkat: AÅŸaÄŸÄ±daki kelimelerin bazÄ±larÄ± sÃ¶zlÃ¼kte yok!
tahmin_et("film fena deÄŸildi")