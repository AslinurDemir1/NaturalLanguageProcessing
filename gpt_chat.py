from transformers import pipeline, set_seed

# --- 1. MODELÄ° Ã‡AÄIRMA ---
# Hugging Face'in "pipeline" Ã¶zelliÄŸi, karmaÅŸÄ±k kodlarÄ± tek satÄ±ra indirir.
# 'text-generation': Metin Ã¼retmek istiyorum diyoruz.
# 'model': KullanacaÄŸÄ±mÄ±z hazÄ±r beyin (Topluluk tarafÄ±ndan eÄŸitilmiÅŸ TÃ¼rkÃ§e GPT-2)
print("Model indiriliyor ve hazÄ±rlanÄ±yor... (Ä°lk seferde uzun sÃ¼rebilir)")

try:
    # TÃ¼rkÃ§e iÃ§in eÄŸitilmiÅŸ popÃ¼ler bir GPT-2 modelini kullanÄ±yoruz
    generator = pipeline('text-generation', model='redrussianarmy/gpt2-turkish-cased')
except Exception as e:
    print(f"Hata oluÅŸtu: {e}")
    print("LÃ¼tfen 'pip install torch transformers' komutunu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±ndan emin ol.")
    exit()

# --- 2. AYARLAR (YARATICILIK DÃœÄMELERÄ°) ---
# set_seed(42) # EÄŸer bunu aÃ§arsan her zaman aynÄ± cevabÄ± verir (Bilimsel deney iÃ§in)

def yazi_yaz(baslangic_cumlesi):
    print(f"\nğŸ“ GiriÅŸ: '{baslangic_cumlesi}'")
    print("-" * 30)
    
    # Model Ã§alÄ±ÅŸÄ±yor...
    # max_length: En fazla kaÃ§ kelime/token yazsÄ±n?
    # num_return_sequences: KaÃ§ farklÄ± varyasyon yazsÄ±n?
    # temperature: YaratÄ±cÄ±lÄ±k ayarÄ±. (0.7 dengeli, 1.5 Ã§Ä±lgÄ±n, 0.1 robotik)
    cikti = generator(baslangic_cumlesi, max_length=100, num_return_sequences=1, temperature=0.9)
    
    # Sonucu temizleyip yazdÄ±ralÄ±m
    uretilen_metin = cikti[0]['generated_text']
    print(f"ğŸ¤– YZ: {uretilen_metin}")
    print("-" * 30)

# --- 3. DENEME ZAMANI ---
yazi_yaz("Yapay zeka mÃ¼hendisliÄŸi okumak")
yazi_yaz("TÃ¼rkiye'nin en gÃ¼zel ÅŸehri")
yazi_yaz("BugÃ¼n hava Ã§ok gÃ¼zel olduÄŸu iÃ§in")